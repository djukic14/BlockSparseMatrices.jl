var documenterSearchIndex = {"docs":
[{"location":"apiref/#API-Reference","page":"API Reference","title":"API Reference","text":"","category":"section"},{"location":"apiref/","page":"API Reference","title":"API Reference","text":"","category":"page"},{"location":"apiref/#BlockSparseMatrices.AbstractBlockMatrix","page":"API Reference","title":"BlockSparseMatrices.AbstractBlockMatrix","text":"abstract type AbstractBlockMatrix{T} <: LinearMap{T}\n\nAbstract type representing a block matrix with element type T. The block matrix is composed of a small number of smaller matrix blocks, allowing for efficient storage and computation.\n\nNotes\n\nThe AbstractBlockMatrix type serves as a base for concrete block matrix implementations, providing a common interface for linear algebra operations.\n\n\n\n\n\n","category":"type"},{"location":"apiref/#BlockSparseMatrices.AbstractMatrixBlock","page":"API Reference","title":"BlockSparseMatrices.AbstractMatrixBlock","text":"abstract type AbstractMatrixBlock{T} <: LinearMap{T}\n\nAbstract type representing a matrix block with element type T. This type inherits from LinearMap{T}, indicating that matrix-vector products can be performed with instances of this type, even when considering a single block in isolation. The dimensions of the vectors involved in the matrix-vector product are the same as the dimensions of the block.\n\nAdditionally, transpose and adjoint operations are also supported.\n\nNotes\n\nThe matrix-vector product operation is well-defined for a single block.\nBoth transpose and adjoint operations are available.\n\n\n\n\n\n","category":"type"},{"location":"apiref/#BlockSparseMatrices.BlockSparseMatrix","page":"API Reference","title":"BlockSparseMatrices.BlockSparseMatrix","text":"struct BlockSparseMatrix{T,M,D,S} <: AbstractBlockMatrix{T}\n\nA concrete implementation of a block sparse matrix, which is a sparse matrix composed of smaller dense matrix blocks.\n\nType Parameters\n\nT: The element type of the matrix.\nM: The type of the matrix blocks.\nD: The type of the row and column index dictionaries.\nS: The type of the scheduler.\n\nFields\n\nblocks: A vector of matrix blocks that comprise the block sparse matrix.\nsize: A tuple representing the size of the block sparse matrix.\nforwardbuffer: A buffer used for forward matrix-vector product computations.\nadjointbuffer: A buffer used for adjoint matrix-vector product computations.\nbuffer: The underlying buffer that is reused for both forward and adjoint products.\nrowindexdict: A dictionary that maps row indices to block indices.\ncolindexdict: A dictionary that maps column indices to block indices.\ncolors: A vector of colors, where each color is a vector of block indices that can be processed in parallel without race conditions.\ntransposecolors: A vector of colors for the transpose matrix, where each color is a vector of block indices that can be processed in parallel without race conditions.\nscheduler: A scheduler that manages the parallel computation of matrix-vector products.\n\n\n\n\n\n","category":"type"},{"location":"apiref/#BlockSparseMatrices.BlockSparseMatrix-Union{Tuple{M}, Tuple{Vector{M}, Tuple{Int64, Int64}}} where M<:BlockSparseMatrices.AbstractMatrixBlock","page":"API Reference","title":"BlockSparseMatrices.BlockSparseMatrix","text":"BlockSparseMatrix(\n    blocks::Vector{M},\n    size::Tuple{Int,Int};\n    coloringalgorithm=coloringalgorithm,\n    scheduler=SerialScheduler(),\n) where {M<:AbstractMatrixBlock}\n\nConstructs a new BlockSparseMatrix instance from the given blocks and size.\n\nArguments\n\nblocks: A vector of AbstractMatrixBlock instances.\nsize: A tuple representing the size of the block sparse matrix.\ncoloringalgorithm: The algorithm from GraphsColoring.jl used to color the blocks for parallel computation. Defaults to coloringalgorithm.\nscheduler: The scheduler used to manage parallel computation. Defaults to SerialScheduler().\n\nReturns\n\nA new BlockSparseMatrix instance constructed from the given blocks and size.\n\n\n\n\n\n","category":"method"},{"location":"apiref/#BlockSparseMatrices.BlockSparseMatrix-Union{Tuple{V}, Tuple{M}, Tuple{Vector{M}, V, V, Tuple{Int64, Int64}}} where {M, V}","page":"API Reference","title":"BlockSparseMatrices.BlockSparseMatrix","text":"BlockSparseMatrix(\n    blocks::Vector{M},\n    rowindices::V,\n    colindices::V,\n    size::Tuple{Int,Int};\n    coloringalgorithm=coloringalgorithm,\n    scheduler=DynamicScheduler(),\n) where {M,V}\n\nConstructs a new BlockSparseMatrix instance from the given blocks, row indices, column indices, and size.\n\nArguments\n\nblocks: A vector of dense matrices.\nrowindices: A vector of row indices corresponding to each block.\ncolindices: A vector of column indices corresponding to each block.\nsize: A tuple representing the size of the block sparse matrix.\ncoloringalgorithm: The algorithm from GraphsColoring.jl used to color the blocks for parallel computation. Defaults to coloringalgorithm.\nscheduler: The scheduler used to manage parallel computation. Defaults to SerialScheduler().\n\nReturns\n\nA new BlockSparseMatrix instance constructed from the given blocks, row indices, column indices, and size.\n\n\n\n\n\n","category":"method"},{"location":"apiref/#BlockSparseMatrices.DenseMatrixBlock","page":"API Reference","title":"BlockSparseMatrices.DenseMatrixBlock","text":"struct DenseMatrixBlock{T,M,RC} <: AbstractMatrixBlock{T}\n\nA concrete implementation of an AbstractMatrixBlock representing a dense matrix block. This struct stores the actual matrix data, as well as the global row and column indices of the block in the sparse block matrix.\n\nType Parameters\n\nT: The element type of the matrix block.\nM: The type of the matrix storage.\nRC: The type of the row and column index collections.\n\nFields\n\nmatrix: The dense matrix stored in the block.\nrowindices: The global row indices of the block in the sparse block matrix.\ncolindices: The global column indices of the block in the sparse block matrix.\n\n\n\n\n\n","category":"type"},{"location":"apiref/#BlockSparseMatrices.DenseMatrixBlock-Union{Tuple{RC}, Tuple{M}, Tuple{M, RC, RC}} where {M, RC<:Vector{Int64}}","page":"API Reference","title":"BlockSparseMatrices.DenseMatrixBlock","text":"DenseMatrixBlock(matrix::M, rowindices::RC, colindices::RC) where {M,RC<:Vector{Int}}\n\nConstructs a new DenseMatrixBlock instance from the given matrix, row indices, and column indices.\n\nArguments\n\nmatrix: The dense matrix to be stored in the block.\nrowindices: The global row indices of the block in the sparse block matrix.\ncolindices: The global column indices of the block in the sparse block matrix.\n\nType Parameters\n\nM: The type of the matrix storage.\nRC: The type of the row and column index collections, which must be a Vector{Int}.\n\nReturns\n\nA new DenseMatrixBlock instance with the specified matrix, row indices, and column indices.\n\nNotes\n\nThe element type of the DenseMatrixBlock instance is inferred from the element type of the input matrix.\n\n\n\n\n\n","category":"method"},{"location":"apiref/#BlockSparseMatrices.SymmetricBlockMatrix","page":"API Reference","title":"BlockSparseMatrices.SymmetricBlockMatrix","text":"struct SymmetricBlockMatrix{T,DM,M,D,S} <: AbstractBlockMatrix{T}\n\nA concrete implementation of a symmetric block matrix, which is a block matrix where the off-diagonal blocks are shared between the upper and lower triangular parts. The diagonal blocks are symmetric as well.\n\nType Parameters\n\nT: The element type of the matrix.\nDM: The type of the diagonal matrix blocks.\nM: The type of the off-diagonal matrix blocks.\nD: The type of the row and column index dictionaries.\nS: The type of the scheduler.\n\nFields\n\ndiagonals: A vector of diagonal matrix blocks.\noffdiagonals: A vector of off-diagonal matrix blocks.\nsize: A tuple representing the size of the symmetric block matrix.\nforwardbuffer: A buffer used for forward matrix-vector product computations.\nadjointbuffer: A buffer used for adjoint matrix-vector product computations.\nbuffer: The underlying buffer that is reused for both forward and adjoint products.\ndiagonalsrowindexdict: A dictionary that maps row indices to diagonal block indices.\ndiagonalscolindexdict: A dictionary that maps column indices to diagonal block indices.\noffdiagonalsrowindexdict: A dictionary that maps row indices to off-diagonal block indices.\noffdiagonalscolindexdict: A dictionary that maps column indices to off-diagonal block indices.\ndiagonalcolors: A vector of colors for the diagonal blocks, where each color is a vector of block indices that can be processed in parallel without race conditions.\noffdiagonalcolors: A vector of colors for the off-diagonal blocks, where each color is a vector of block indices that can be processed in parallel without race conditions.\ntransposeoffdiagonalcolors: A vector of colors for the transposed off-diagonal blocks, where each color is a vector of block indices that can be processed in parallel without race conditions.\nscheduler: A scheduler that manages the parallel computation of matrix-vector products.\n\n\n\n\n\n","category":"type"},{"location":"apiref/#BlockSparseMatrices.SymmetricBlockMatrix-Union{Tuple{M}, Tuple{DM}, Tuple{Vector{DM}, Vector{M}, Tuple{Int64, Int64}}} where {DM<:BlockSparseMatrices.AbstractMatrixBlock, M<:BlockSparseMatrices.AbstractMatrixBlock}","page":"API Reference","title":"BlockSparseMatrices.SymmetricBlockMatrix","text":"SymmetricBlockMatrix(\n    diagonals::Vector{DM},\n    offdiagonals::Vector{M},\n    size::Tuple{Int,Int};\n    scheduler=DynamicScheduler(),\n) where {DM<:AbstractMatrixBlock,M<:AbstractMatrixBlock}\n\nConstructs a new SymmetricBlockMatrix instance from the given diagonal and off-diagonal blocks, and size.\n\nArguments\n\ndiagonals: A vector of AbstractMatrixBlock instances.\noffdiagonals: A vector of AbstractMatrixBlock instances.\nsize: A tuple representing the size of the symmetric block matrix.\nscheduler: The scheduler used to manage parallel computation. Defaults to DynamicScheduler().\n\nReturns\n\nA new SymmetricBlockMatrix instance constructed from the given blocks and size.\n\n\n\n\n\n","category":"method"},{"location":"apiref/#BlockSparseMatrices.SymmetricBlockMatrix-Union{Tuple{V}, Tuple{M}, Tuple{DM}, Tuple{Vector{DM}, V, Vector{M}, V, V, Tuple{Int64, Int64}}} where {DM, M, V}","page":"API Reference","title":"BlockSparseMatrices.SymmetricBlockMatrix","text":"SymmetricBlockMatrix(\n    diagonals::Vector{DM},\n    diagonalindices::V,\n    offdiagonals::Vector{M},\n    rowindices::V,\n    columnindices::V,\n    size::Tuple{Int,Int};\n    scheduler=DynamicScheduler(),\n) where {DM,M,V}\n\nConstructs a new SymmetricBlockMatrix instance from the given diagonal and off-diagonal blocks, indices, and size.\n\nArguments\n\ndiagonals: A vector of symmetric dense matrices.\ndiagonalindices: A vector of indices corresponding to the diagonal blocks.\noffdiagonals: A vector of dense matrices.\nrowindices: A vector of row indices corresponding to the off-diagonal blocks.\ncolumnindices: A vector of column indices corresponding to the off-diagonal blocks.\nsize: A tuple representing the size of the symmetric block matrix.\nscheduler: The scheduler used to manage parallel computation. Defaults to DynamicScheduler().\n\nReturns\n\nA new SymmetricBlockMatrix instance constructed from the given blocks, indices, and size.\n\n\n\n\n\n","category":"method"},{"location":"apiref/#BlockSparseMatrices.block-Tuple{BlockSparseMatrix, Any}","page":"API Reference","title":"BlockSparseMatrices.block","text":"block(A::BlockSparseMatrix, i)\n\nReturns the i-th block of the given BlockSparseMatrix instance.\n\nArguments\n\nA: The BlockSparseMatrix instance to query.\ni: The index of the block to retrieve.\n\nReturns\n\nThe i-th block of the BlockSparseMatrix.\n\n\n\n\n\n","category":"method"},{"location":"apiref/#BlockSparseMatrices.buffer-Tuple{BlockSparseMatrices.AbstractBlockMatrix}","page":"API Reference","title":"BlockSparseMatrices.buffer","text":"buffer(A::AbstractBlockMatrix)\n\nReturns the buffer associated with the given AbstractBlockMatrix instance for the matrix-vector product.\n\n\n\n\n\n","category":"method"},{"location":"apiref/#BlockSparseMatrices.buffers-Union{Tuple{T}, Tuple{Type{T}, Any, Any}} where T","page":"API Reference","title":"BlockSparseMatrices.buffers","text":"buffers(::Type{T}, rows, cols) where {T}\n\nAllocates and returns a set of buffers for efficient matrix-vector product computations. The buffers are designed to minimize memory allocation and copying, reducing computational overhead.\n\nArguments\n\nT: The element type of the buffers.\nrows: The number of rows in the matrix.\ncols: The number of columns in the matrix.\n\nReturns\n\nA tuple containing:\nforwardbuffer: A view of the buffer for forward matrix-vector products, with length rows.\nadjointbuffer: A view of the buffer for adjoint matrix-vector products, with length cols.\nbuffer: The underlying buffer, which is reused for both forward and adjoint products.\n\nNotes\n\nThe buffer is allocated with a length equal to the maximum of rows and cols, ensuring sufficient storage for both forward and adjoint products.\nThe forwardbuffer and adjointbuffer views are created using unsafe_wrap, which means that they overlap and share the same memory.\n\n\n\n\n\n","category":"method"},{"location":"apiref/#BlockSparseMatrices.colblockids-Tuple{BlockSparseMatrices.AbstractBlockMatrix, Integer}","page":"API Reference","title":"BlockSparseMatrices.colblockids","text":"colblockids(A::AbstractBlockMatrix, j::Integer)\n\nReturns the indices of the blocks in the AbstractBlockMatrix instance that contain the given column index j.\n\nArguments\n\nA: The AbstractBlockMatrix instance to query.\nj: The column index to search for.\n\nReturns\n\nA collection of block indices that contain the column index j.\n\n\n\n\n\n","category":"method"},{"location":"apiref/#BlockSparseMatrices.colindices-Tuple{BlockSparseMatrices.AbstractMatrixBlock}","page":"API Reference","title":"BlockSparseMatrices.colindices","text":"colindices(block::AbstractMatrixBlock)\n\nReturns the global column indices of the matrix block in the sparse block matrix.\n\nNotes\n\nThe returned indices are global indices in the sparse block matrix, not local indices inside the block.\n\n\n\n\n\n","category":"method"},{"location":"apiref/#BlockSparseMatrices.colors-Tuple{BlockSparseMatrix}","page":"API Reference","title":"BlockSparseMatrices.colors","text":"colors(A::BlockSparseMatrix)\n\nReturns the colors used for multithreading in matrix-vector for the given BlockSparseMatrix. These colors are created using GraphsColoring.jl and represent a partitioning of the blocks into sets that can be processed in parallel without race conditions.\n\nArguments\n\nA: The BlockSparseMatrix instance to query.\n\nReturns\n\nA collection of colors, where each color is a vector of block indices that can be processed in parallel.\n\n\n\n\n\n","category":"method"},{"location":"apiref/#BlockSparseMatrices.conflictindices-Tuple{BlockSparseMatrices.AbstractMatrixBlock}","page":"API Reference","title":"BlockSparseMatrices.conflictindices","text":"conflictindices(block::AbstractMatrixBlock; transpose=false)\n\nReturns the conflict indices for a given AbstractMatrixBlock object. These indices represent the memory locations that are accessed by the block during a matrix-vector product.\n\nArguments\n\nblock: The AbstractMatrixBlock object for which to compute the conflict indices.\ntranspose: A boolean flag indicating whether to consider the transpose of the block. Defaults to false.\n\nReturns\n\nA collection of indices representing the memory locations that are accessed by the block.\n\nNotes\n\nIf transpose is false, the function returns the row indices of the block, as these correspond to the memory locations accessed during a standard matrix-vector product.\nIf transpose is true, the function returns the column indices of the block, as these correspond to the memory locations accessed during a transposed (and adjoint) matrix-vector product.\n\n\n\n\n\n","category":"method"},{"location":"apiref/#BlockSparseMatrices.denseblocks-Union{Tuple{V}, Tuple{M}, Tuple{Vector{M}, V, V}} where {M, V}","page":"API Reference","title":"BlockSparseMatrices.denseblocks","text":"denseblocks(blocks::Vector{M}, rowindices::V, colindices::V) where {M,V}\n\nConstructs a vector of DenseMatrixBlock instances from the given blocks, row indices, and column indices.\n\nArguments\n\nblocks: A vector of matrix blocks.\nrowindices: A vector of global row indices corresponding to each block.\ncolindices: A vector of global column indices corresponding to each block.\n\nType Parameters\n\nM: The type of the matrix blocks.\nV: The type of the row and column index vectors.\n\nReturns\n\nA vector of DenseMatrixBlock instances, where each instance corresponds to a block in the input blocks vector.\n\nNotes\n\nThe element type of the DenseMatrixBlock instances is inferred from the element type of the input blocks.\nThe rowindices and colindices vectors are assumed to have the same length as the blocks vector.\n\n\n\n\n\n","category":"method"},{"location":"apiref/#BlockSparseMatrices.diagonal-Tuple{SymmetricBlockMatrix, Any}","page":"API Reference","title":"BlockSparseMatrices.diagonal","text":"diagonal(A::SymmetricBlockMatrix, i)\n\nReturns the i-th diagonal block of the given SymmetricBlockMatrix instance.\n\nArguments\n\nA: The SymmetricBlockMatrix instance to query.\ni: The index of the diagonal block to retrieve.\n\nReturns\n\nThe i-th diagonal block of the SymmetricBlockMatrix.\n\n\n\n\n\n","category":"method"},{"location":"apiref/#BlockSparseMatrices.diagonalcolindices-Tuple{SymmetricBlockMatrix, Integer}","page":"API Reference","title":"BlockSparseMatrices.diagonalcolindices","text":"diagonalcolindices(A::SymmetricBlockMatrix, j::Integer)\n\nReturns the indices of the diagonal blocks in the given SymmetricBlockMatrix instance that contain the column index j.\n\nArguments\n\nA: The SymmetricBlockMatrix instance to query.\nj: The column index to search for.\n\nReturns\n\nA vector of indices of the diagonal blocks that contain the column index j. If no such blocks exist, an empty vector is returned.\n\n\n\n\n\n","category":"method"},{"location":"apiref/#BlockSparseMatrices.diagonalcolors-Tuple{SymmetricBlockMatrix}","page":"API Reference","title":"BlockSparseMatrices.diagonalcolors","text":"diagonalcolors(A::SymmetricBlockMatrix)\n\nReturns the colors used for the diagonal blocks of the given SymmetricBlockMatrix instance. These colors are used to coordinate parallel computation and avoid race conditions.\n\nArguments\n\nA: The SymmetricBlockMatrix instance to query.\n\nReturns\n\nA vector of colors, where each color is a vector of diagonal block indices that can be processed in parallel without race conditions.\n\n\n\n\n\n","category":"method"},{"location":"apiref/#BlockSparseMatrices.diagonalrowindices-Tuple{SymmetricBlockMatrix, Integer}","page":"API Reference","title":"BlockSparseMatrices.diagonalrowindices","text":"diagonalrowindices(A::SymmetricBlockMatrix, i::Integer)\n\nReturns the indices of the diagonal blocks in the given SymmetricBlockMatrix instance that contain the row index i.\n\nArguments\n\nA: The SymmetricBlockMatrix instance to query.\ni: The row index to search for.\n\nReturns\n\nA vector of indices of the diagonal blocks that contain the row index i. If no such blocks exist, an empty vector is returned.\n\n\n\n\n\n","category":"method"},{"location":"apiref/#BlockSparseMatrices.eachblockindex-Tuple{BlockSparseMatrix}","page":"API Reference","title":"BlockSparseMatrices.eachblockindex","text":"eachblockindex(A::BlockSparseMatrix)\n\nReturns an iterator over the indices of the blocks in the given BlockSparseMatrix instance.\n\nArguments\n\nA: The BlockSparseMatrix instance to query.\n\nReturns\n\nAn iterator that yields the indices of the blocks in the BlockSparseMatrix.\n\n\n\n\n\n","category":"method"},{"location":"apiref/#BlockSparseMatrices.eachdiagonalindex-Tuple{SymmetricBlockMatrix}","page":"API Reference","title":"BlockSparseMatrices.eachdiagonalindex","text":"eachdiagonalindex(A::SymmetricBlockMatrix)\n\nReturns an iterator over the indices of the diagonal blocks in the given SymmetricBlockMatrix instance.\n\nArguments\n\nA: The SymmetricBlockMatrix instance to query.\n\nReturns\n\nAn iterator that yields the indices of the diagonal blocks in the SymmetricBlockMatrix.\n\n\n\n\n\n","category":"method"},{"location":"apiref/#BlockSparseMatrices.eachoffdiagonalindex-Tuple{SymmetricBlockMatrix}","page":"API Reference","title":"BlockSparseMatrices.eachoffdiagonalindex","text":"eachoffdiagonalindex(A::SymmetricBlockMatrix)\n\nReturns an iterator over the indices of the off-diagonal blocks in the given SymmetricBlockMatrix instance.\n\nArguments\n\nA: The SymmetricBlockMatrix instance to query.\n\nReturns\n\nAn iterator that yields the indices of the off-diagonal blocks in the SymmetricBlockMatrix.\n\n\n\n\n\n","category":"method"},{"location":"apiref/#BlockSparseMatrices.islessinordering-Tuple{BlockSparseMatrices.AbstractMatrixBlock, BlockSparseMatrices.AbstractMatrixBlock}","page":"API Reference","title":"BlockSparseMatrices.islessinordering","text":"islessinordering(blocka::AbstractMatrixBlock, blockb::AbstractMatrixBlock)\n\nDefines a sorting rule for AbstractMatrixBlock objects. This function determines the order of two blocks based on their row and column indices.\n\nReturns\n\ntrue if blocka is considered less than blockb according to the sorting rule, false otherwise.\n\nSorting Rule\n\nBlocks are first compared based on the maximum row index. If the maximum row index of blocka is less than that of blockb, blocka is considered less than blockb.\nIf the maximum row indices are equal, the blocks are compared based on the maximum column index. If the maximum column index of blocka is less than that of blockb, blocka is considered less than blockb.\n\n\n\n\n\n","category":"method"},{"location":"apiref/#BlockSparseMatrices.matrix-Tuple{BlockSparseMatrices.AbstractMatrixBlock}","page":"API Reference","title":"BlockSparseMatrices.matrix","text":"matrix(block::AbstractMatrixBlock)\n\nReturns the content of the matrix block.\n\nReturns\n\nmatrix: The actual matrix stored in the block.\n\nNotes\n\nThis function provides direct access to the matrix data, allowing for further manipulation.\n\n\n\n\n\n","category":"method"},{"location":"apiref/#BlockSparseMatrices.offdiagonal-Tuple{SymmetricBlockMatrix, Any}","page":"API Reference","title":"BlockSparseMatrices.offdiagonal","text":"offdiagonal(A::SymmetricBlockMatrix, i)\n\nReturns the i-th off-diagonal block of the given SymmetricBlockMatrix instance.\n\nArguments\n\nA: The SymmetricBlockMatrix instance to query.\ni: The index of the off-diagonal block to retrieve.\n\nReturns\n\nThe i-th off-diagonal block of the SymmetricBlockMatrix.\n\n\n\n\n\n","category":"method"},{"location":"apiref/#BlockSparseMatrices.offdiagonalcolors-Tuple{SymmetricBlockMatrix}","page":"API Reference","title":"BlockSparseMatrices.offdiagonalcolors","text":"offdiagonalcolors(A::SymmetricBlockMatrix)\n\nReturns the colors used for the off-diagonal blocks of the given SymmetricBlockMatrix instance. These colors are used to coordinate parallel computation and avoid race conditions.\n\nArguments\n\nA: The SymmetricBlockMatrix instance to query.\n\nReturns\n\nA vector of colors, where each color is a vector of off-diagonal block indices that can be processed in parallel without race conditions.\n\n\n\n\n\n","category":"method"},{"location":"apiref/#BlockSparseMatrices.offdiagonalrowindices-Tuple{SymmetricBlockMatrix, Integer}","page":"API Reference","title":"BlockSparseMatrices.offdiagonalrowindices","text":"offdiagonalrowindices(A::SymmetricBlockMatrix, i::Integer)\n\nReturns the indices of the off-diagonal blocks in the given SymmetricBlockMatrix instance that contain the row index i.\n\nArguments\n\nA: The SymmetricBlockMatrix instance to query.\ni: The row index to search for.\n\nReturns\n\nA vector of indices of the off-diagonal blocks that contain the row index i. If no such blocks exist, an empty vector is returned.\n\n\n\n\n\n","category":"method"},{"location":"apiref/#BlockSparseMatrices.rowblockids-Tuple{BlockSparseMatrices.AbstractBlockMatrix, Integer}","page":"API Reference","title":"BlockSparseMatrices.rowblockids","text":"rowblockids(A::AbstractBlockMatrix, i::Integer)\n\nReturns the indices of the blocks in the AbstractBlockMatrix instance that contain the given row index i.\n\nArguments\n\nA: The AbstractBlockMatrix instance to query.\ni: The row index to search for.\n\nReturns\n\nA collection of block indices that contain the row index i.\n\n\n\n\n\n","category":"method"},{"location":"apiref/#BlockSparseMatrices.rowcolvals-Union{Tuple{M}, Tuple{Z}} where {Z<:BlockSparseMatrix, M<:Union{LinearMaps.AdjointMap{<:Any, Z}, LinearMaps.TransposeMap{<:Any, Z}, Z}}","page":"API Reference","title":"BlockSparseMatrices.rowcolvals","text":"rowcolvals(A)\n\nExtracts the row, column, and value indices from a block-sparse matrix A such that a sparse matrix can be constructed.\n\nArguments\n\nA: A block-sparse matrix.\n\nReturns\n\nrows: An array of row indices.\ncols: An array of column indices.\nvals: An array of values.\n\n\n\n\n\n","category":"method"},{"location":"apiref/#BlockSparseMatrices.rowindices-Tuple{BlockSparseMatrices.AbstractMatrixBlock}","page":"API Reference","title":"BlockSparseMatrices.rowindices","text":"rowindices(block::AbstractMatrixBlock)\n\nReturns the global row indices of the matrix block in the sparse block matrix.\n\nNotes\n\nThe returned indices are global indices in the sparse block matrix, not local indices inside the block.\n\n\n\n\n\n","category":"method"},{"location":"apiref/#BlockSparseMatrices.scheduler-Tuple{BlockSparseMatrices.AbstractBlockMatrix}","page":"API Reference","title":"BlockSparseMatrices.scheduler","text":"scheduler(A::AbstractBlockMatrix)\n\nReturns the scheduler associated with the given AbstractBlockMatrix instance. This scheduler is responsible for managing the parallel computation of matrix-vector products.\n\nReturns\n\nThe scheduler associated with the matrix.\n\nNotes\n\nThe scheduler is used to coordinate the computation of matrix-vector product.\n\n\n\n\n\n","category":"method"},{"location":"apiref/#BlockSparseMatrices.transposecolors-Tuple{BlockSparseMatrix}","page":"API Reference","title":"BlockSparseMatrices.transposecolors","text":"colors(A::BlockSparseMatrix)\n\nReturns the colors used for multithreading in the transposed matrix-vector product computations for the given BlockSparseMatrix. These colors are created using GraphsColoring.jl and represent a partitioning of the blocks into sets that can be processed in parallel without race conditions.\n\nArguments\n\nA: The BlockSparseMatrix instance to query.\n\nReturns\n\nA collection of colors, where each color is a vector of block indices that can be processed in parallel.\n\n\n\n\n\n","category":"method"},{"location":"apiref/#BlockSparseMatrices.transposeoffdiagonalcolors-Tuple{SymmetricBlockMatrix}","page":"API Reference","title":"BlockSparseMatrices.transposeoffdiagonalcolors","text":"transposeoffdiagonalcolors(A::SymmetricBlockMatrix)\n\nReturns the colors used for the transposed off-diagonal blocks of the given SymmetricBlockMatrix instance. These colors are used to coordinate parallel computation and avoid race conditions when computing the transpose of the matrix.\n\nArguments\n\nA: The SymmetricBlockMatrix instance to query.\n\nReturns\n\nA vector of colors, where each color is a vector of transposed off-diagonal block indices that can be processed in parallel without race conditions.\n\n\n\n\n\n","category":"method"},{"location":"apiref/#GraphsColoring.conflicts-Union{Tuple{Vector{A}}, Tuple{A}} where A<:BlockSparseMatrices.AbstractMatrixBlock","page":"API Reference","title":"GraphsColoring.conflicts","text":"conflicts(blocks::Vector{A}; kwargs...) where {A<:AbstractMatrixBlock}\n\nComputes the conflicts between blocks for the purpose of graph coloring using GraphsColoring.jl. This function is used to determine the coloring of blocks for multithreading in the matrix-vector product, ensuring that blocks with no conflicts can be processed in parallel.\n\nArguments\n\nblocks: A vector of AbstractMatrixBlock objects.\nkwargs...: Additional keyword arguments passed to the conflictindices function.\n\nNotes\n\nBlocks with no conflicts (i.e., blocks that do not overlap in their conflict indices) can be processed in parallel.\nThe colors are used to group blocks into sets that can be processed in parallel, avoiding race conditions and ensuring efficient multithreading in the matrix-vector product.\n\n\n\n\n\n","category":"method"},{"location":"contributing/#Contributing","page":"Contributing","title":"Contributing","text":"","category":"section"},{"location":"contributing/","page":"Contributing","title":"Contributing","text":"In order to contribute to this package directly create a pull request against the main branch. Before doing so please: ","category":"page"},{"location":"contributing/","page":"Contributing","title":"Contributing","text":"Follow the style of the surrounding code.\nSupplement the documentation.\nWrite tests and check that no errors occur.","category":"page"},{"location":"contributing/","page":"Contributing","title":"Contributing","text":"","category":"page"},{"location":"contributing/#Style","page":"Contributing","title":"Style","text":"","category":"section"},{"location":"contributing/","page":"Contributing","title":"Contributing","text":"For a consistent style the JuliaFormatter.jl package is used which enforces the style defined in the .JuliaFormatter.toml file. To follow this style simply run","category":"page"},{"location":"contributing/","page":"Contributing","title":"Contributing","text":"using JuliaFormatter\nformat(pkgdir(BlockSparseMatrices))","category":"page"},{"location":"contributing/","page":"Contributing","title":"Contributing","text":"note: Note\nThat all files follow the JuliaFormatter style is tested during the unit tests. Hence, do not forget to execute the two lines above. Otherwise, the tests are likely to not pass.","category":"page"},{"location":"contributing/","page":"Contributing","title":"Contributing","text":"","category":"page"},{"location":"contributing/#Documentation","page":"Contributing","title":"Documentation","text":"","category":"section"},{"location":"contributing/","page":"Contributing","title":"Contributing","text":"Add documentation for any changes or new features following the style of the existing documentation. For more information you can have a look at the Documenter.jl documentation.","category":"page"},{"location":"contributing/","page":"Contributing","title":"Contributing","text":"","category":"page"},{"location":"contributing/#tests","page":"Contributing","title":"Tests","text":"","category":"section"},{"location":"contributing/","page":"Contributing","title":"Contributing","text":"Write tests for your code changes and verify that no errors occur, e.g., by running","category":"page"},{"location":"contributing/","page":"Contributing","title":"Contributing","text":"using Pkg\nPkg.test(\"BlockSparseMatrices.jl\")","category":"page"},{"location":"contributing/","page":"Contributing","title":"Contributing","text":"For a detailed information on which parts are tested the coverage can be evaluated on your local machine, e.g., by","category":"page"},{"location":"contributing/","page":"Contributing","title":"Contributing","text":"using Pkg\nPkg.test(\"BlockSparseMatrices\"; coverage=true, julia_args=[\"-t 4\"])\n\n# determine coverage\nusing Coverage\nsrc_folder = pkgdir(BlockSparseMatrices) * \"/src\"\ncoverage   = process_folder(src_folder)\nLCOV.writefile(\"path-to-folder-you-like\" * \"BlockSparseMatrices.lcov.info\", coverage)\n\nclean_folder(src_folder) # delete .cov files\n\n# extract information about coverage\ncovered_lines, total_lines = get_summary(coverage)\n@info \"Current coverage:\\n$covered_lines of $total_lines lines ($(round(Int, covered_lines / total_lines * 100)) %)\"","category":"page"},{"location":"contributing/","page":"Contributing","title":"Contributing","text":"In Visual Studio Code the Coverage Gutters plugin can be used to visualize the tested lines of the code by inserting the path of the BlockSparseMatrices.lcov.info file in the settings.","category":"page"},{"location":"block/#BlockSparseMatrix","page":"BlockSparseMatrix","title":"BlockSparseMatrix","text":"","category":"section"},{"location":"block/","page":"BlockSparseMatrix","title":"BlockSparseMatrix","text":"A BlockSparseMatrix is a matrices that is (at least) sparse at the block level.   This can, for example, occur when the matrix originates from a fast multipole method (FMM) or any other algorithm that naturally groups rows and columns into interacting blocks (e.g. near‑field interactions).","category":"page"},{"location":"block/","page":"BlockSparseMatrix","title":"BlockSparseMatrix","text":"Below you will find a compact, step‑by‑step guide that shows how to","category":"page"},{"location":"block/","page":"BlockSparseMatrix","title":"BlockSparseMatrix","text":"Build a block‑sparse matrix from a list of dense blocks and their index maps.  \nMultiply it with vectors (including transposes).  \nConvert it to a standard SparseMatrixCSC for comparison.  \nEnable multi‑threaded construction with OhMyThreads.","category":"page"},{"location":"block/","page":"BlockSparseMatrix","title":"BlockSparseMatrix","text":"","category":"page"},{"location":"block/#Constructing-a-BlockSparseMatrix","page":"BlockSparseMatrix","title":"Constructing a BlockSparseMatrix","text":"","category":"section"},{"location":"block/","page":"BlockSparseMatrix","title":"BlockSparseMatrix","text":"using CompScienceMeshes, BEAST, H2Trees\nusing UnicodePlots\nusing BlockSparseMatrices\n\nm = meshsphere(1.0, 0.1)\nX = raviartthomas(m)\ntree = TwoNTree(X, 0.2)\ncolvalues, rowvalues = H2Trees.nearinteractions(tree)\n\nblocks = Matrix{Float64}[]\nfor i in eachindex(colvalues)\n    push!(blocks, randn(Float64, length(colvalues[i]), length(rowvalues[i])))\nend\n\nB = BlockSparseMatrix(blocks, colvalues, rowvalues, (numfunctions(X), numfunctions(X)))","category":"page"},{"location":"block/","page":"BlockSparseMatrix","title":"BlockSparseMatrix","text":"B now behaves like a regular matrix: you can query its size, inspect its blocks, etc.","category":"page"},{"location":"block/#Matrix–Vector-Products","page":"BlockSparseMatrix","title":"Matrix–Vector Products","text":"","category":"section"},{"location":"block/","page":"BlockSparseMatrix","title":"BlockSparseMatrix","text":"using CompScienceMeshes, BEAST, H2Trees # hide\nusing UnicodePlots # hide\nusing BlockSparseMatrices # hide\n\nm = meshsphere(1.0, 0.1) # hide\nX = raviartthomas(m) # hide\ntree = TwoNTree(X, 0.2) # hide\ncolvalues, rowvalues = H2Trees.nearinteractions(tree) # hide\n\nblocks = Matrix{Float64}[] # hide\nfor i in eachindex(colvalues) # hide\n    push!(blocks, randn(Float64, length(colvalues[i]), length(rowvalues[i]))) # hide\nend # hide\n\nB = BlockSparseMatrix(blocks, colvalues, rowvalues, (numfunctions(X), numfunctions(X))) # hide\n\ny = randn(Float64, size(B, 1))\n@time B * y\n@time B' * y\n@time transpose(B) * y\nnothing # hide","category":"page"},{"location":"block/","page":"BlockSparseMatrix","title":"BlockSparseMatrix","text":"All three operations are implemented in pure Julia and respect the block‑sparsity, so they are typically much faster than converting the matrix to a dense format first.","category":"page"},{"location":"block/#Converting-to-a-Classical-Sparse-Matrix","page":"BlockSparseMatrix","title":"Converting to a Classical Sparse Matrix","text":"","category":"section"},{"location":"block/","page":"BlockSparseMatrix","title":"BlockSparseMatrix","text":"Sometimes you need a SparseMatrixCSC. The conversion is straightforward. You can compare the memory footprints:","category":"page"},{"location":"block/","page":"BlockSparseMatrix","title":"BlockSparseMatrix","text":"using CompScienceMeshes, BEAST, H2Trees # hide\nusing UnicodePlots # hide\nusing BlockSparseMatrices # hide\n\nm = meshsphere(1.0, 0.1) # hide\nX = raviartthomas(m) # hide\ntree = TwoNTree(X, 0.2) # hide\ncolvalues, rowvalues = H2Trees.nearinteractions(tree) # hide\n\nblocks = Matrix{Float64}[] # hide\nfor i in eachindex(colvalues) # hide\n    push!(blocks, randn(Float64, length(colvalues[i]), length(rowvalues[i]))) # hide\nend # hide\n\nB = BlockSparseMatrix(blocks, colvalues, rowvalues, (numfunctions(X), numfunctions(X))) # hide\n\nusing SparseArrays\nBsparse = sparse(B)\n\n@show Base.format_bytes(Base.summarysize(B));\n@show Base.format_bytes(Base.summarysize(Bsparse));\nnothing # hide","category":"page"},{"location":"block/","page":"BlockSparseMatrix","title":"BlockSparseMatrix","text":"In specific examples BlockSparseMatrix consumes less memory.","category":"page"},{"location":"block/#Multi‑Threaded-Construction-(Optional)","page":"BlockSparseMatrix","title":"Multi‑Threaded Construction (Optional)","text":"","category":"section"},{"location":"block/","page":"BlockSparseMatrix","title":"BlockSparseMatrix","text":"Depending on the example, the block-coloring step can be a bottleneck, thus multithreading is switched-off by default. To enable multithreading you can determine a scheduler from OhMyThreads.","category":"page"},{"location":"block/","page":"BlockSparseMatrix","title":"BlockSparseMatrix","text":"using CompScienceMeshes, BEAST, H2Trees # hide\nusing UnicodePlots # hide\nusing BlockSparseMatrices # hide\n\nm = meshsphere(1.0, 0.1) # hide\nX = raviartthomas(m) # hide\ntree = TwoNTree(X, 0.2) # hide\ncolvalues, rowvalues = H2Trees.nearinteractions(tree) # hide\n\nblocks = Matrix{Float64}[] # hide\nfor i in eachindex(colvalues) # hide\n    push!(blocks, randn(Float64, length(colvalues[i]), length(rowvalues[i]))) # hide\nend # hide\n\nusing OhMyThreads\nB = BlockSparseMatrix(\n    blocks,\n    colvalues,\n    rowvalues,\n    (numfunctions(X), numfunctions(X));\n    scheduler=DynamicScheduler(),\n)\n\nnothing # hide","category":"page"},{"location":"#BlockSparseMatrices.jl","page":"Introduction","title":"BlockSparseMatrices.jl","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"BlockSparseMatrices.jl provides a representation for sparse matrices that are composed of a limited number of (dense) blocks.   It also includes specialized algorithms for symmetric block‑sparse matrices, storing only the necessary half of the off‑diagonal blocks.  ","category":"page"},{"location":"#Key-Features","page":"Introduction","title":"Key Features","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"Block‑sparse storage – the matrix is built from a small set of (dense) sub‑blocks.  \nSymmetric support – for symmetric block‑sparse matrices only the lower (or upper) triangular block‑structure is kept, reducing memory usage.  \nMultithreaded matrix–vector multiplication – leverages  OhMyThreads and GraphsColoring for safe parallelism.  ","category":"page"},{"location":"#Implemented-Operations","page":"Introduction","title":"Implemented Operations","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"Operation Description\n* (matrix‑vector product) Fast, multithreaded multiplication.\ntranspose / adjoint Returns the (adjoint) transpose of a block‑sparse matrix.\ngetindex Access individual elements of the matrix.\nsetindex! Modify elements in‑place.\nVisualization Visual inspection via UnicodePlots.\nsparse Convert to a standard SparseMatrixCSC from SparseArrays.","category":"page"},{"location":"#Related-Packages","page":"Introduction","title":"Related Packages","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"If you need alternative block‑matrix representations or additional functionality, consider:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"BlockArrays\nBlockMatrices\nBlockDiagonals\nBlockBandedMatrices","category":"page"},{"location":"symmetric/#SymmetricBlockMatrix","page":"SymmetricBlockMatrix","title":"SymmetricBlockMatrix","text":"","category":"section"},{"location":"symmetric/","page":"SymmetricBlockMatrix","title":"SymmetricBlockMatrix","text":"A SymmetricBlockMatrix is a matrices that is symmetric and (at least) sparse at the block level.   This can, for example, occur when the matrix originates from a fast multipole method (FMM) or any other algorithm that naturally groups rows and columns into interacting blocks (e.g. near‑field interactions).","category":"page"},{"location":"symmetric/","page":"SymmetricBlockMatrix","title":"SymmetricBlockMatrix","text":"note: Note\nNo sanity check is performed that makes sure that not both blocks of a pair of symmetric blocks are stored.","category":"page"},{"location":"symmetric/","page":"SymmetricBlockMatrix","title":"SymmetricBlockMatrix","text":"Below you will find a compact, step‑by‑step guide that shows how to","category":"page"},{"location":"symmetric/","page":"SymmetricBlockMatrix","title":"SymmetricBlockMatrix","text":"Build a symmetric block‑sparse matrix from two lists of dense blocks and their index maps.  \nMultiply it with vectors (including transposes).  \nConvert it to a standard SparseMatrixCSC for comparison.  \nEnable multi‑threaded construction with OhMyThreads.","category":"page"},{"location":"symmetric/","page":"SymmetricBlockMatrix","title":"SymmetricBlockMatrix","text":"","category":"page"},{"location":"symmetric/#Constructing-a-SymmetricBlockMatrix","page":"SymmetricBlockMatrix","title":"Constructing a SymmetricBlockMatrix","text":"","category":"section"},{"location":"symmetric/","page":"SymmetricBlockMatrix","title":"SymmetricBlockMatrix","text":"using CompScienceMeshes, BEAST, H2Trees\nusing UnicodePlots\nusing BlockSparseMatrices\n\n# make sure that only one of the two symmetric  blocks is stored\nstruct GalerkinSymmetricIsNearFunctor{N}\n    isnear::N\nend\n\nfunction (f::GalerkinSymmetricIsNearFunctor)(tree, nodea, nodeb)\n    if H2Trees.isleaf(tree, nodeb)\n        return f.isnear(tree, nodea, nodeb) && nodea > nodeb\n    else\n        return f.isnear(tree, nodea, nodeb)\n    end\nend\n\nm = meshsphere(1.0, 0.1)\nX = raviartthomas(m)\nsizeS = (numfunctions(X), numfunctions(X))\ntree = TwoNTree(X, 0.2)\n\nselfvalues, colvalues, rowvalues = H2Trees.nearinteractions(\n    tree; extractselfvalues=true, isnear=GalerkinSymmetricIsNearFunctor(H2Trees.isnear)\n)\n\ndiagonals = Matrix{Float64}[]\nfor i in eachindex(selfvalues)\n    push!(diagonals, rand(Float64, length(selfvalues[i]), length(selfvalues[i])))\n    diagonals[end] = (diagonals[end] + transpose(diagonals[end])) / 2  # diagonals are symmetric\nend\n\noffdiagonals = Matrix{Float64}[]\nfor i in eachindex(colvalues)\n    push!(offdiagonals, rand(Float64, length(colvalues[i]), length(rowvalues[i])))\nend\n\nS = SymmetricBlockMatrix(diagonals, selfvalues, offdiagonals, colvalues, rowvalues, sizeS)","category":"page"},{"location":"symmetric/","page":"SymmetricBlockMatrix","title":"SymmetricBlockMatrix","text":"S now behaves like a regular matrix: you can query its size, inspect its blocks, etc.","category":"page"},{"location":"symmetric/#Matrix–Vector-Products","page":"SymmetricBlockMatrix","title":"Matrix–Vector Products","text":"","category":"section"},{"location":"symmetric/","page":"SymmetricBlockMatrix","title":"SymmetricBlockMatrix","text":"using CompScienceMeshes, BEAST, H2Trees # hide\nusing UnicodePlots # hide\nusing BlockSparseMatrices # hide\n\n# make sure that only one of the two symmetric  blocks is stored # hide\nstruct GalerkinSymmetricIsNearFunctor{N} # hide\n    isnear::N # hide\nend # hide\n\nfunction (f::GalerkinSymmetricIsNearFunctor)(tree, nodea, nodeb) # hide\n    if H2Trees.isleaf(tree, nodeb) # hide\n        return f.isnear(tree, nodea, nodeb) && nodea > nodeb # hide\n    else # hide\n        return f.isnear(tree, nodea, nodeb) # hide\n    end # hide\nend # hide\n\nm = meshsphere(1.0, 0.1) # hide\nX = raviartthomas(m) # hide\nsizeS = (numfunctions(X), numfunctions(X)) # hide\ntree = TwoNTree(X, 0.2) # hide\n\nselfvalues, colvalues, rowvalues = H2Trees.nearinteractions( # hide\n    tree; extractselfvalues=true, isnear=GalerkinSymmetricIsNearFunctor(H2Trees.isnear) # hide\n) # hide\n\ndiagonals = Matrix{Float64}[] # hide\nfor i in eachindex(selfvalues) # hide\n    push!(diagonals, rand(Float64, length(selfvalues[i]), length(selfvalues[i]))) # hide\n    diagonals[end] = (diagonals[end] + transpose(diagonals[end])) / 2  # diagonals are symmetric # hide\nend # hide\n\noffdiagonals = Matrix{Float64}[] # hide\nfor i in eachindex(colvalues) # hide\n    push!(offdiagonals, rand(Float64, length(colvalues[i]), length(rowvalues[i]))) # hide\nend # hide\n\nS = SymmetricBlockMatrix(diagonals, selfvalues, offdiagonals, colvalues, rowvalues, sizeS) # hide\n\ny = randn(Float64, numfunctions(X))\n@time S * y\n@time S' * y\n@time transpose(S) * y\n@show maximum(abs, S * y - transpose(S) * y)\nnothing # hide","category":"page"},{"location":"symmetric/","page":"SymmetricBlockMatrix","title":"SymmetricBlockMatrix","text":"All three operations are implemented in pure Julia and respect the block‑sparsity, so they are typically much faster than converting the matrix to a dense format first.","category":"page"},{"location":"symmetric/#Converting-to-a-Classical-Sparse-Matrix","page":"SymmetricBlockMatrix","title":"Converting to a Classical Sparse Matrix","text":"","category":"section"},{"location":"symmetric/","page":"SymmetricBlockMatrix","title":"SymmetricBlockMatrix","text":"Sometimes you need a SparseMatrixCSC. The conversion is straightforward. You can compare the memory footprints:","category":"page"},{"location":"symmetric/","page":"SymmetricBlockMatrix","title":"SymmetricBlockMatrix","text":"using CompScienceMeshes, BEAST, H2Trees # hide\nusing UnicodePlots # hide\nusing BlockSparseMatrices # hide\n\n# make sure that only one of the two symmetric  blocks is stored # hide\nstruct GalerkinSymmetricIsNearFunctor{N} # hide\n    isnear::N # hide\nend # hide\n\nfunction (f::GalerkinSymmetricIsNearFunctor)(tree, nodea, nodeb) # hide\n    if H2Trees.isleaf(tree, nodeb) # hide\n        return f.isnear(tree, nodea, nodeb) && nodea > nodeb # hide\n    else # hide\n        return f.isnear(tree, nodea, nodeb) # hide\n    end # hide\nend # hide\n\nm = meshsphere(1.0, 0.1) # hide\nX = raviartthomas(m) # hide\nsizeS = (numfunctions(X), numfunctions(X)) # hide\ntree = TwoNTree(X, 0.2) # hide\n\nselfvalues, colvalues, rowvalues = H2Trees.nearinteractions( # hide\n    tree; extractselfvalues=true, isnear=GalerkinSymmetricIsNearFunctor(H2Trees.isnear) # hide\n) # hide\n\ndiagonals = Matrix{Float64}[] # hide\nfor i in eachindex(selfvalues) # hide\n    push!(diagonals, rand(Float64, length(selfvalues[i]), length(selfvalues[i]))) # hide\n    diagonals[end] = (diagonals[end] + transpose(diagonals[end])) / 2  # diagonals are symmetric # hide\nend # hide\n\noffdiagonals = Matrix{Float64}[] # hide\nfor i in eachindex(colvalues) # hide\n    push!(offdiagonals, rand(Float64, length(colvalues[i]), length(rowvalues[i]))) # hide\nend # hide\n\nS = SymmetricBlockMatrix(diagonals, selfvalues, offdiagonals, colvalues, rowvalues, sizeS) # hide\n\nusing SparseArrays\nSsparse = sparse(S)\ndisplay(Ssparse);\n\n@show Base.format_bytes(Base.summarysize(S))\n@show Base.format_bytes(Base.summarysize(Ssparse))\nnothing # hide","category":"page"},{"location":"symmetric/","page":"SymmetricBlockMatrix","title":"SymmetricBlockMatrix","text":"In specific examples SymmetricBlockMatrix consumes less memory.","category":"page"},{"location":"symmetric/#Multi‑Threaded-Construction-(Optional)","page":"SymmetricBlockMatrix","title":"Multi‑Threaded Construction (Optional)","text":"","category":"section"},{"location":"symmetric/","page":"SymmetricBlockMatrix","title":"SymmetricBlockMatrix","text":"Depending on the example, the block-coloring step can be a bottleneck, thus multithreading is switched-off by default. To enable multithreading you can determine a scheduler from OhMyThreads.","category":"page"},{"location":"symmetric/","page":"SymmetricBlockMatrix","title":"SymmetricBlockMatrix","text":"using CompScienceMeshes, BEAST, H2Trees # hide\nusing UnicodePlots # hide\nusing BlockSparseMatrices # hide\n\n# make sure that only one of the two symmetric  blocks is stored  # hide\nstruct GalerkinSymmetricIsNearFunctor{N} # hide\n    isnear::N # hide\nend # hide\n\nfunction (f::GalerkinSymmetricIsNearFunctor)(tree, nodea, nodeb) # hide\n    if H2Trees.isleaf(tree, nodeb) # hide\n        return f.isnear(tree, nodea, nodeb) && nodea > nodeb # hide\n    else # hide\n        return f.isnear(tree, nodea, nodeb) # hide\n    end # hide\nend # hide\n\nm = meshsphere(1.0, 0.1) # hide\nX = raviartthomas(m) # hide\nsizeS = (numfunctions(X), numfunctions(X)) # hide\ntree = TwoNTree(X, 0.2) # hide\n\nselfvalues, colvalues, rowvalues = H2Trees.nearinteractions(  # hide\n    tree; extractselfvalues=true, isnear=GalerkinSymmetricIsNearFunctor(H2Trees.isnear)  # hide\n) # hide\n\ndiagonals = Matrix{Float64}[] # hide\nfor i in eachindex(selfvalues) # hide\n    push!(diagonals, rand(Float64, length(selfvalues[i]), length(selfvalues[i]))) # hide\n    diagonals[end] = (diagonals[end] + transpose(diagonals[end])) / 2  # diagonals are symmetric  # hide\nend  # hide\n\noffdiagonals = Matrix{Float64}[] # hide\nfor i in eachindex(colvalues) # hide\n    push!(offdiagonals, rand(Float64, length(colvalues[i]), length(rowvalues[i]))) # hide\nend # hide\n\nusing OhMyThreads\nS = SymmetricBlockMatrix(\n    diagonals,\n    selfvalues,\n    offdiagonals,\n    colvalues,\n    rowvalues,\n    sizeS;\n    scheduler=DynamicScheduler(),\n)\nnothing # hide","category":"page"}]
}
